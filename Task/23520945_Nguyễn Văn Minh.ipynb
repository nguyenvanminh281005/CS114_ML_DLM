{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2ec21ef",
   "metadata": {},
   "source": [
    "23520945 - Nguyễn Văn Minh\n",
    "1. Bộ dataset fetch_california_housing\n",
    "2. Bộ dataset diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "33ea4981",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "550"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "a = np.random.randint(1,945)\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0716c05",
   "metadata": {},
   "source": [
    "# Dataset fetch_california_housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "4201c884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Sklearn LinearRegression (fit_intercept=True):\n",
      "Intercept: 2.072132\n",
      "Coefficients: ['0.823720', '0.120027', '-0.250624', '0.287773', '-0.005015', '-0.049609', '-0.902299', '-0.872670']\n",
      "Test MSE: 0.496499\n",
      "\n",
      "2. Sklearn LinearRegression (fit_intercept=False):\n",
      "Intercept (first coef): 2.072132\n",
      "Coefficients: ['0.823720', '0.120027', '-0.250624', '0.287773', '-0.005015', '-0.049609', '-0.902299', '-0.872670']\n",
      "Test MSE: 0.496499\n",
      "\n",
      "3. Mathematical Equation (Normal Equation):\n",
      "Intercept: 2.072132\n",
      "Coefficients: ['0.823720', '0.120027', '-0.250624', '0.287773', '-0.005015', '-0.049609', '-0.902299', '-0.872670']\n",
      "Test MSE: 0.496499\n",
      "\n",
      "4. Gradient Descent:\n",
      "Intercept: 2.073096\n",
      "Coefficients: ['0.816552', '0.178065', '-0.127947', '0.140932', '0.016562', '-0.052676', '-0.486784', '-0.451661']\n",
      "Test MSE: 0.527058\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load dataset\n",
    "housing = fetch_california_housing()\n",
    "X = housing.data\n",
    "y = housing.target\n",
    "m = X.shape[0]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=945)\n",
    "\n",
    "# 1. Using sklearn with fit_intercept=True\n",
    "print(\"1. Sklearn LinearRegression (fit_intercept=True):\")\n",
    "lr_true = LinearRegression(fit_intercept=True)\n",
    "lr_true.fit(X_train, y_train)\n",
    "print(f\"Intercept: {lr_true.intercept_:.6f}\")\n",
    "print(\"Coefficients:\", [f\"{coef:.6f}\" for coef in lr_true.coef_])\n",
    "print(f\"Test MSE: {np.mean((y_test - lr_true.predict(X_test)) ** 2):.6f}\\n\")\n",
    "\n",
    "# 2. Using sklearn with fit_intercept=False\n",
    "print(\"2. Sklearn LinearRegression (fit_intercept=False):\")\n",
    "lr_false = LinearRegression(fit_intercept=False)\n",
    "X_train_no_intercept = np.c_[np.ones(len(X_train)), X_train]  # Add bias term manually\n",
    "X_test_no_intercept = np.c_[np.ones(len(X_test)), X_test]\n",
    "lr_false.fit(X_train_no_intercept, y_train)\n",
    "print(f\"Intercept (first coef): {lr_false.coef_[0]:.6f}\")  # First coef is intercept\n",
    "print(\"Coefficients:\", [f\"{coef:.6f}\" for coef in lr_false.coef_[1:]])\n",
    "print(f\"Test MSE: {np.mean((y_test - lr_false.predict(X_test_no_intercept)) ** 2):.6f}\\n\")\n",
    "\n",
    "# 3. Using Mathematical Equation (Normal Equation)\n",
    "print(\"3. Mathematical Equation (Normal Equation):\")\n",
    "X_train_bias = np.c_[np.ones(len(X_train)), X_train]  # Add bias term\n",
    "# Normal equation: beta = (X^T X)^(-1) X^T y\n",
    "beta_math = np.linalg.inv(X_train_bias.T @ X_train_bias) @ X_train_bias.T @ y_train\n",
    "X_test_bias = np.c_[np.ones(len(X_test)), X_test]\n",
    "y_test_pred_math = X_test_bias @ beta_math\n",
    "print(f\"Intercept: {beta_math[0]:.6f}\")\n",
    "print(\"Coefficients:\", [f\"{coef:.6f}\" for coef in beta_math[1:]])\n",
    "print(f\"Test MSE: {np.mean((y_test - y_test_pred_math) ** 2):.6f}\\n\")\n",
    "\n",
    "# 4. Using Gradient Descent\n",
    "print(\"4. Gradient Descent:\")\n",
    "n_features = X_train.shape[1]\n",
    "beta_gd = np.zeros(n_features + 1)  # +1 for intercept\n",
    "X_train_bias = np.c_[np.ones(len(X_train)), X_train]\n",
    "X_test_bias = np.c_[np.ones(len(X_test)), X_test]\n",
    "learning_rate = 0.01\n",
    "n_epochs = 1000\n",
    "tolerance = 1e-6\n",
    "\n",
    "prev_mse = float('inf')\n",
    "for epoch in range(n_epochs):\n",
    "    y_pred = X_train_bias @ beta_gd\n",
    "    error = y_pred - y_train\n",
    "    gradient = (X_train_bias.T @ error) / len(y_train)\n",
    "    beta_gd -= learning_rate * gradient\n",
    "    mse = np.mean(error ** 2)\n",
    "    if abs(prev_mse - mse) < tolerance:\n",
    "        print(f\"Converged at epoch {epoch}\")\n",
    "        break\n",
    "    prev_mse = mse\n",
    "\n",
    "y_test_pred_gd = X_test_bias @ beta_gd\n",
    "print(f\"Intercept: {beta_gd[0]:.6f}\")\n",
    "print(\"Coefficients:\", [f\"{coef:.6f}\" for coef in beta_gd[1:]])\n",
    "print(f\"Test MSE: {np.mean((y_test - y_test_pred_gd) ** 2):.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "492905ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Sklearn LinearRegression (fit_intercept=True):\n",
      "Intercept: 2.072132\n",
      "Coefficients: ['0.823720', '0.120027', '-0.250624', '0.287773', '-0.005015', '-0.049609', '-0.902299', '-0.872670']\n",
      "Test MSE: 0.496499\n",
      "\n",
      "3. Sklearn LinearRegression (fit_intercept=False, no bias):\n",
      "Intercept: 0 (forced through origin)\n",
      "Coefficients: ['0.833846', '0.118220', '-0.276561', '0.315347', '-0.012174', '-0.058174', '-0.922821', '-0.889839']\n",
      "Test MSE: 4.719344\n"
     ]
    }
   ],
   "source": [
    "# Load California housing dataset\n",
    "housing = fetch_california_housing()\n",
    "X = housing.data  # Features\n",
    "y = housing.target  # Target (median house value)\n",
    "\n",
    "# Normalize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=945)\n",
    "\n",
    "# 1. Sklearn LinearRegression with fit_intercept=True\n",
    "print(\"1. Sklearn LinearRegression (fit_intercept=True):\")\n",
    "lr_true = LinearRegression(fit_intercept=True)\n",
    "lr_true.fit(X_train, y_train)\n",
    "print(f\"Intercept: {lr_true.intercept_:.6f}\")\n",
    "print(\"Coefficients:\", [f\"{coef:.6f}\" for coef in lr_true.coef_])\n",
    "print(f\"Test MSE: {np.mean((y_test - lr_true.predict(X_test)) ** 2):.6f}\\n\")\n",
    "\n",
    "# 2. Sklearn LinearRegression with fit_intercept=False (no manual bias column)\n",
    "print(\"3. Sklearn LinearRegression (fit_intercept=False, no bias):\")\n",
    "lr_false_no_bias = LinearRegression(fit_intercept=False)\n",
    "lr_false_no_bias.fit(X_train, y_train)\n",
    "print(f\"Intercept: 0 (forced through origin)\")\n",
    "print(\"Coefficients:\", [f\"{coef:.6f}\" for coef in lr_false_no_bias.coef_])\n",
    "print(f\"Test MSE: {np.mean((y_test - lr_false_no_bias.predict(X_test)) ** 2):.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3671f259",
   "metadata": {},
   "source": [
    "# Dataset Diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "6c49326c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Sklearn LinearRegression (fit_intercept=True):\n",
      "Intercept: 149.839809\n",
      "Coefficients: ['-0.067681', '-13.923691', '22.790689', '17.957027', '-36.256090', '20.734863', '6.632618', '10.095416', '34.623477', '5.139578']\n",
      "Test MSE: 2628.264864\n",
      "\n",
      "2. Sklearn LinearRegression (fit_intercept=False):\n",
      "Intercept (first coef): 149.839809\n",
      "Coefficients: ['-0.067681', '-13.923691', '22.790689', '17.957027', '-36.256090', '20.734863', '6.632618', '10.095416', '34.623477', '5.139578']\n",
      "Test MSE: 2628.264864\n",
      "\n",
      "3. Mathematical Equation (Normal Equation):\n",
      "Intercept: 149.839809\n",
      "Coefficients: ['-0.067681', '-13.923691', '22.790689', '17.957027', '-36.256090', '20.734863', '6.632618', '10.095416', '34.623477', '5.139578']\n",
      "Test MSE: 2628.264864\n",
      "\n",
      "4. Gradient Descent:\n",
      "Intercept: 149.751529\n",
      "Coefficients: ['-0.149362', '-13.955018', '22.985817', '17.692469', '-3.678376', '-4.856855', '-8.265943', '5.559332', '22.680287', '5.301838']\n",
      "Test MSE: 2658.421215\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load diabetes dataset\n",
    "diabetes = load_diabetes()\n",
    "X = diabetes.data\n",
    "y = diabetes.target\n",
    "m = X.shape[0]\n",
    "\n",
    "# Normalize features (for consistency across methods)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=23520945)\n",
    "\n",
    "# 1. Using sklearn with fit_intercept=True\n",
    "print(\"1. Sklearn LinearRegression (fit_intercept=True):\")\n",
    "lr_true = LinearRegression(fit_intercept=True)\n",
    "lr_true.fit(X_train, y_train)\n",
    "print(f\"Intercept: {lr_true.intercept_:.6f}\")\n",
    "print(\"Coefficients:\", [f\"{coef:.6f}\" for coef in lr_true.coef_])\n",
    "print(f\"Test MSE: {np.mean((y_test - lr_true.predict(X_test)) ** 2):.6f}\\n\")\n",
    "\n",
    "# 2. Using sklearn with fit_intercept=False\n",
    "print(\"2. Sklearn LinearRegression (fit_intercept=False):\")\n",
    "lr_false = LinearRegression(fit_intercept=False)\n",
    "X_train_no_intercept = np.c_[np.ones(len(X_train)), X_train]  # Add bias term manually\n",
    "X_test_no_intercept = np.c_[np.ones(len(X_test)), X_test]\n",
    "lr_false.fit(X_train_no_intercept, y_train)\n",
    "print(f\"Intercept (first coef): {lr_false.coef_[0]:.6f}\")  # First coef is intercept\n",
    "print(\"Coefficients:\", [f\"{coef:.6f}\" for coef in lr_false.coef_[1:]])\n",
    "print(f\"Test MSE: {np.mean((y_test - lr_false.predict(X_test_no_intercept)) ** 2):.6f}\\n\")\n",
    "\n",
    "# 3. Using Mathematical Equation (Normal Equation)\n",
    "print(\"3. Mathematical Equation (Normal Equation):\")\n",
    "X_train_bias = np.c_[np.ones(len(X_train)), X_train]  # Add bias term\n",
    "# Normal equation: beta = (X^T X)^(-1) X^T y\n",
    "beta_math = np.linalg.inv(X_train_bias.T @ X_train_bias) @ X_train_bias.T @ y_train\n",
    "X_test_bias = np.c_[np.ones(len(X_test)), X_test]\n",
    "y_test_pred_math = X_test_bias @ beta_math\n",
    "print(f\"Intercept: {beta_math[0]:.6f}\")\n",
    "print(\"Coefficients:\", [f\"{coef:.6f}\" for coef in beta_math[1:]])\n",
    "print(f\"Test MSE: {np.mean((y_test - y_test_pred_math) ** 2):.6f}\\n\")\n",
    "\n",
    "# 4. Using Gradient Descent\n",
    "print(\"4. Gradient Descent:\")\n",
    "n_features = X_train.shape[1]\n",
    "beta_gd = np.zeros(n_features + 1)  # +1 for intercept\n",
    "X_train_bias = np.c_[np.ones(len(X_train)), X_train]\n",
    "X_test_bias = np.c_[np.ones(len(X_test)), X_test]\n",
    "learning_rate = 0.01\n",
    "n_epochs = 1000\n",
    "tolerance = 1e-6\n",
    "\n",
    "prev_mse = float('inf')\n",
    "for epoch in range(n_epochs):\n",
    "    y_pred = X_train_bias @ beta_gd\n",
    "    error = y_pred - y_train\n",
    "    gradient = (X_train_bias.T @ error) / len(y_train)\n",
    "    beta_gd -= learning_rate * gradient\n",
    "    mse = np.mean(error ** 2)\n",
    "    if abs(prev_mse - mse) < tolerance:\n",
    "        break\n",
    "    prev_mse = mse\n",
    "\n",
    "y_test_pred_gd = X_test_bias @ beta_gd\n",
    "print(f\"Intercept: {beta_gd[0]:.6f}\")\n",
    "print(\"Coefficients:\", [f\"{coef:.6f}\" for coef in beta_gd[1:]])\n",
    "print(f\"Test MSE: {np.mean((y_test - y_test_pred_gd) ** 2):.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "a38601f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_intercept=True:\n",
      "Intercept: 151.345605\n",
      "Coefficients: ['37.904021', '-241.964362', '542.428759', '347.703844', '-931.488846', '518.062277', '163.419983', '275.317902', '736.198859', '48.670657']\n",
      "Test MSE: 2900.193628\n",
      "\n",
      "fit_intercept=False:\n",
      "Intercept: 0 (forced through origin)\n",
      "Coefficients: ['125.210295', '-258.201028', '627.487246', '346.313102', '-803.348768', '312.915931', '45.123164', '211.988946', '700.881751', '144.687142']\n",
      "Test MSE: 27961.756917\n"
     ]
    }
   ],
   "source": [
    "# Without normalization and without manual bias column for fit_intercept=False\n",
    "X_raw = diabetes.data  # Raw data\n",
    "X_train_raw, X_test_raw, y_train, y_test = train_test_split(X_raw, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# fit_intercept=True\n",
    "lr_true = LinearRegression(fit_intercept=True)\n",
    "lr_true.fit(X_train_raw, y_train)\n",
    "print(\"fit_intercept=True:\")\n",
    "print(f\"Intercept: {lr_true.intercept_:.6f}\")\n",
    "print(\"Coefficients:\", [f\"{coef:.6f}\" for coef in lr_true.coef_])\n",
    "print(f\"Test MSE: {np.mean((y_test - lr_true.predict(X_test_raw)) ** 2):.6f}\\n\")\n",
    "\n",
    "# fit_intercept=False (no bias column)\n",
    "lr_false = LinearRegression(fit_intercept=False)\n",
    "lr_false.fit(X_train_raw, y_train)\n",
    "print(\"fit_intercept=False:\")\n",
    "print(f\"Intercept: 0 (forced through origin)\")\n",
    "print(\"Coefficients:\", [f\"{coef:.6f}\" for coef in lr_false.coef_])\n",
    "print(f\"Test MSE: {np.mean((y_test - lr_false.predict(X_test_raw)) ** 2):.6f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GPU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
